{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('./dataset'):\n",
    "    for filename in filenames:\n",
    "        filepath = os.path.join(dirname, filename)\n",
    "        print(f\"Processing file: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data & Data Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_files = []\n",
    "\n",
    "for year in range(2022, 2025):\n",
    "    year_files = [files for files in os.listdir('./dataset') if f'_{year}-' in files]\n",
    "    year_files.sort() \n",
    "    \n",
    "    for file in year_files:\n",
    "        path_files.append(pandas.read_parquet('./dataset/' + file))\n",
    "        \n",
    "print(f\"Loaded {len(path_files)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.concat(path_files, ignore_index=True)\n",
    "print(f\"Total rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['base_passenger_fare'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['base_passenger_fare'] >= 0) & (df['base_passenger_fare'] < 100)]\n",
    "print(f\"Rows after filtering by fare: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['airport_fee'] == 0]\n",
    "print(f\"Rows after removing airport fee: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['hvfhs_license_num', 'request_datetime','trip_miles','trip_time', 'base_passenger_fare', 'tips']]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['request_hour'] = df['request_datetime'].dt.hour\n",
    "df['request_day_of_week'] = df['request_datetime'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "df['hvfhs_license_num_encoded'] = encoder.fit_transform(df['hvfhs_license_num'])\n",
    "df = df.drop(columns=['hvfhs_license_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Feature Correlations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting Data (Train, Validation, Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train: Days 1–20\n",
    "train_data = df[df['request_datetime'].dt.day <= 20]\n",
    "\n",
    "# Validation: Days 21–25\n",
    "validation_data = df[(df['request_datetime'].dt.day >= 21) & (df['request_datetime'].dt.day <= 25)]\n",
    "\n",
    "# Test: Days 26–end of the month\n",
    "test_data = df[df['request_datetime'].dt.day >= 26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=['request_datetime'])\n",
    "validation_data = validation_data.drop(columns=['request_datetime'])\n",
    "test_data = test_data.drop(columns=['request_datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['trip_miles', 'trip_time', 'base_passenger_fare', 'tips']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Training data\n",
    "train_data_scaled = train_data.copy()\n",
    "train_data_scaled[columns_to_scale] = scaler.fit_transform(train_data[columns_to_scale])\n",
    "\n",
    "# Validation data\n",
    "validation_data_scaled = validation_data.copy()\n",
    "validation_data_scaled[columns_to_scale] = scaler.transform(validation_data[columns_to_scale])\n",
    "\n",
    "# Test data\n",
    "test_data_scaled = test_data.copy()\n",
    "test_data_scaled[columns_to_scale] = scaler.transform(test_data[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Data Sample:\")\n",
    "train_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation Data Sample:\")\n",
    "validation_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['trip_miles', 'trip_time', 'base_passenger_fare', 'tips']] = scaler.fit_transform(\n",
    "    df[['trip_miles', 'trip_time', 'base_passenger_fare', 'tips']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(target_column):\n",
    "    X_train = train_data.drop(columns=[target_column])\n",
    "    y_train = train_data[target_column]\n",
    "\n",
    "    X_val = validation_data.drop(columns=[target_column])\n",
    "    y_val = validation_data[target_column]\n",
    "\n",
    "    X_test = test_data.drop(columns=[target_column])\n",
    "    y_test = test_data[target_column]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model with Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(neurons, optimizer, dropout_rate):\n",
    "    model = Sequential()\n",
    "    for n in neurons:\n",
    "        model.add(Dense(n, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))  # Regression output\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_grid_search(X_train, y_train, param_grid, cv=3):\n",
    "    best_params = None\n",
    "    best_score = float('inf')\n",
    "\n",
    "    for neurons in param_grid['neurons']:\n",
    "        for optimizer in param_grid['optimizer']:\n",
    "            for dropout_rate in param_grid['dropout_rate']:\n",
    "                for batch_size in param_grid['batch_size']:\n",
    "                    for epochs in param_grid['epochs']:\n",
    "                        print(f\"Training with: neurons={neurons}, optimizer={optimizer.__class__.__name__}, dropout_rate={dropout_rate}, \"\n",
    "                              f\"batch_size={batch_size}, epochs={epochs}\")\n",
    "                        \n",
    "                        # Train model\n",
    "                        model = build_model(neurons=neurons, optimizer=optimizer, dropout_rate=dropout_rate)\n",
    "                        history = model.fit(\n",
    "                            X_train, y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=0,\n",
    "                            validation_split=1/cv\n",
    "                        )\n",
    "                        \n",
    "                        # Evaluate with validation loss\n",
    "                        val_loss = history.history['val_loss'][-1]\n",
    "                        if val_loss < best_score:\n",
    "                            best_score = val_loss\n",
    "                            best_params = {\n",
    "                                'neurons': neurons,\n",
    "                                'optimizer': optimizer.__class__.__name__,\n",
    "                                'dropout_rate': dropout_rate,\n",
    "                                'batch_size': batch_size,\n",
    "                                'epochs': epochs\n",
    "                            }\n",
    "\n",
    "    print(\"Best Parameters:\", str(best_params))\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(target_column, neurons, optimizer, dropout_rate, batch_size, epochs):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = prepare_data(target_column)\n",
    "    model = build_model(neurons=neurons, optimizer=optimizer, dropout_rate=dropout_rate)\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = numpy.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    print(f\"Target: {target_column} | MSE: {mse:.2f} | MAE: {mae:.2f}\")\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, name):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'{name} Model Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['mae'], label='Training MAE')\n",
    "    plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "    plt.title(f'{name} Model Mean Absolute Error (MAE)')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Passenger Fare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = prepare_data('base_passenger_fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'neurons': [(128, 64, 32), (64, 32)],\n",
    "    'optimizer': [Adam(), RMSprop()],\n",
    "    'dropout_rate': [0.2, 0.3, 0.4],\n",
    "    'batch_size': [32, 64],\n",
    "    'epochs': [2]\n",
    "}\n",
    "\n",
    "best_params = custom_grid_search(X_train, y_train, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model, base_history = train_and_evaluate(\n",
    "    target_column='base_passenger_fare',\n",
    "    neurons=best_params['neurons'],\n",
    "    optimizer=best_params['optimizer'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    batch_size=best_params['batch_size'],\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(base_history, 'Base Passenger Fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Fare Predictions For Uber/Lyft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "license_plates = {'HV0003': 'Uber', 'HV0005': 'Lyft'}\n",
    "license_plates_encoded = {encoder.transform([plate])[0]: company for plate, company in license_plates.items()}\n",
    "target_column = 'base_passenger_fare'\n",
    "\n",
    "for encoded_plate, company in license_plates_encoded.items():\n",
    "    group_data = test_data_scaled[test_data_scaled['hvfhs_license_num_encoded'] == encoded_plate]\n",
    "    \n",
    "    X_group = group_data.drop(columns=[target_column])\n",
    "    y_group_true = group_data[target_column]\n",
    "    \n",
    "    y_group_pred = base_model.predict(X_group)\n",
    "    \n",
    "    group_mse = numpy.sqrt(mean_squared_error(y_group_true, y_group_pred))\n",
    "    group_mae = mean_absolute_error(y_group_true, y_group_pred)\n",
    "    \n",
    "    print(f\"{company} - MSE: {group_mse:.2f}, MAE: {group_mae:.2f}\")\n",
    "    \n",
    "    # Plot true vs. predicted fares\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(y_group_true, y_group_pred, alpha=0.5, label=f\"{company} Predictions\")\n",
    "    plt.plot([y_group_true.min(), y_group_true.max()], [y_group_true.min(), y_group_true.max()], 'r--', label='Ideal Prediction')\n",
    "    plt.title(f\"True vs. Predicted Base Passenger Fare for {company}\")\n",
    "    plt.xlabel('True Fare')\n",
    "    plt.ylabel('Predicted Fare')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Accuracy by Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_scaled['request_hour'] = test_data['request_hour']\n",
    "\n",
    "# Group by hour and compute average MSE\n",
    "hourly_mse = test_data_scaled.groupby('request_hour', group_keys=False).apply(\n",
    "    lambda group: numpy.sqrt(mean_squared_error(group[target_column], base_model.predict(group.drop(columns=[target_column]))))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot hourly MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "hourly_mse.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Hourly MSE for Fare Predictions')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('MSE')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = prepare_data('tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'neurons': [(128, 64, 32), (64, 32)],\n",
    "    'optimizer': [Adam(), RMSprop()],\n",
    "    'dropout_rate': [0.2, 0.3, 0.4],\n",
    "    'batch_size': [32, 64],\n",
    "    'epochs': [2]\n",
    "}\n",
    "\n",
    "best_params = custom_grid_search(X_train, y_train, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_model, tips_history = train_and_evaluate(\n",
    "    target_column='base_passenger_fare',\n",
    "    neurons=best_params['neurons'],\n",
    "    optimizer=best_params['optimizer'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    batch_size=best_params['batch_size'],\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(tips_history, 'Tips')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
