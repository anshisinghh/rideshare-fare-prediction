{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./dataset\\fhvhv_tripdata_2022-01.parquet\n",
      "Processing file: ./dataset\\fhvhv_tripdata_2022-02.parquet\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('./dataset'):\n",
    "    for filename in filenames:\n",
    "        filepath = os.path.join(dirname, filename)\n",
    "        print(f\"Processing file: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 files.\n"
     ]
    }
   ],
   "source": [
    "path_files = []\n",
    "\n",
    "for year in range(2022, 2025):\n",
    "    year_files = [files for files in os.listdir('./dataset') if f'_{year}-' in files]\n",
    "    year_files.sort() \n",
    "    \n",
    "    for file in year_files:\n",
    "        path_files.append(pandas.read_parquet('./dataset/' + file))\n",
    "        \n",
    "print(f\"Loaded {len(path_files)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 30770874\n"
     ]
    }
   ],
   "source": [
    "df = pandas.concat(path_files, ignore_index=True)\n",
    "print(f\"Total rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.077087e+07\n",
       "mean     2.041490e+01\n",
       "std      1.598893e+01\n",
       "min     -5.201100e+02\n",
       "25%      1.029000e+01\n",
       "50%      1.609000e+01\n",
       "75%      2.502000e+01\n",
       "max      4.995960e+03\n",
       "Name: base_passenger_fare, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "df['base_passenger_fare'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after filtering by fare: 30589303\n"
     ]
    }
   ],
   "source": [
    "df = df[(df['base_passenger_fare'] >= 0) & (df['base_passenger_fare'] < 100)]\n",
    "print(f\"Rows after filtering by fare: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after removing airport fee: 28799598\n"
     ]
    }
   ],
   "source": [
    "df = df[df['airport_fee'] == 0]\n",
    "print(f\"Rows after removing airport fee: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28799598</td>\n",
       "      <td>28799598</td>\n",
       "      <td>28799598</td>\n",
       "      <td>2.879960e+07</td>\n",
       "      <td>2.879960e+07</td>\n",
       "      <td>2.879960e+07</td>\n",
       "      <td>2.879960e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-02-01 05:06:40.889685</td>\n",
       "      <td>2022-02-01 05:11:13.478900</td>\n",
       "      <td>2022-02-01 05:27:50.942393</td>\n",
       "      <td>4.022582e+00</td>\n",
       "      <td>1.000048e+03</td>\n",
       "      <td>1.859486e+01</td>\n",
       "      <td>7.175391e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2021-12-31 22:55:05</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>2022-01-01 00:02:49</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2022-01-17 19:52:30</td>\n",
       "      <td>2022-01-17 19:56:07.250000</td>\n",
       "      <td>2022-01-17 20:10:11</td>\n",
       "      <td>1.480000e+00</td>\n",
       "      <td>5.480000e+02</td>\n",
       "      <td>9.970000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-02-02 08:48:51</td>\n",
       "      <td>2022-02-02 08:54:44</td>\n",
       "      <td>2022-02-02 09:16:13</td>\n",
       "      <td>2.633000e+00</td>\n",
       "      <td>8.450000e+02</td>\n",
       "      <td>1.537000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2022-02-15 14:59:04</td>\n",
       "      <td>2022-02-15 15:03:53</td>\n",
       "      <td>2022-02-15 15:22:44</td>\n",
       "      <td>5.045000e+00</td>\n",
       "      <td>1.279000e+03</td>\n",
       "      <td>2.323000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2022-03-01 00:10:00</td>\n",
       "      <td>2022-02-28 23:59:59</td>\n",
       "      <td>2022-03-01 01:38:23</td>\n",
       "      <td>3.611130e+02</td>\n",
       "      <td>9.915200e+04</td>\n",
       "      <td>9.999000e+01</td>\n",
       "      <td>2.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.030963e+00</td>\n",
       "      <td>6.415795e+02</td>\n",
       "      <td>1.176026e+01</td>\n",
       "      <td>2.048696e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 request_datetime             pickup_datetime  \\\n",
       "count                    28799598                    28799598   \n",
       "mean   2022-02-01 05:06:40.889685  2022-02-01 05:11:13.478900   \n",
       "min           2021-12-31 22:55:05         2022-01-01 00:00:00   \n",
       "25%           2022-01-17 19:52:30  2022-01-17 19:56:07.250000   \n",
       "50%           2022-02-02 08:48:51         2022-02-02 08:54:44   \n",
       "75%           2022-02-15 14:59:04         2022-02-15 15:03:53   \n",
       "max           2022-03-01 00:10:00         2022-02-28 23:59:59   \n",
       "std                           NaN                         NaN   \n",
       "\n",
       "                 dropoff_datetime    trip_miles     trip_time  \\\n",
       "count                    28799598  2.879960e+07  2.879960e+07   \n",
       "mean   2022-02-01 05:27:50.942393  4.022582e+00  1.000048e+03   \n",
       "min           2022-01-01 00:02:49  0.000000e+00  0.000000e+00   \n",
       "25%           2022-01-17 20:10:11  1.480000e+00  5.480000e+02   \n",
       "50%           2022-02-02 09:16:13  2.633000e+00  8.450000e+02   \n",
       "75%           2022-02-15 15:22:44  5.045000e+00  1.279000e+03   \n",
       "max           2022-03-01 01:38:23  3.611130e+02  9.915200e+04   \n",
       "std                           NaN  4.030963e+00  6.415795e+02   \n",
       "\n",
       "       base_passenger_fare          tips  \n",
       "count         2.879960e+07  2.879960e+07  \n",
       "mean          1.859486e+01  7.175391e-01  \n",
       "min           0.000000e+00  0.000000e+00  \n",
       "25%           9.970000e+00  0.000000e+00  \n",
       "50%           1.537000e+01  0.000000e+00  \n",
       "75%           2.323000e+01  0.000000e+00  \n",
       "max           9.999000e+01  2.000000e+02  \n",
       "std           1.176026e+01  2.048696e+00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['hvfhs_license_num', 'request_datetime', 'pickup_datetime','dropoff_datetime','trip_miles','trip_time', 'base_passenger_fare', 'tips']]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['request_hour'] = df['request_datetime'].dt.hour\n",
    "df['request_day_of_week'] = df['request_datetime'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "df['hvfhs_license_num_encoded'] = encoder.fit_transform(df['hvfhs_license_num'])\n",
    "df = df.drop(columns=['hvfhs_license_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting Data (Train, Validation, Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[df['request_datetime'].dt.day <= 20]\n",
    "\n",
    "# Validation: Days 21–25\n",
    "validation_data = df[(df['request_datetime'].dt.day >= 21) & (df['request_datetime'].dt.day <= 25)]\n",
    "\n",
    "# Test: Days 26–end of the month\n",
    "test_data = df[df['request_datetime'].dt.day >= 26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=['request_datetime', 'pickup_datetime', 'dropoff_datetime'])\n",
    "validation_data = validation_data.drop(columns=['request_datetime', 'pickup_datetime', 'dropoff_datetime'])\n",
    "test_data = test_data.drop(columns=['request_datetime', 'pickup_datetime', 'dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['trip_miles', 'trip_time', 'base_passenger_fare', 'tips']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Training data\n",
    "train_data_scaled = train_data.copy()\n",
    "train_data_scaled[columns_to_scale] = scaler.fit_transform(train_data[columns_to_scale])\n",
    "\n",
    "# Validation data\n",
    "validation_data_scaled = validation_data.copy()\n",
    "validation_data_scaled[columns_to_scale] = scaler.transform(validation_data[columns_to_scale])\n",
    "\n",
    "# Test data\n",
    "test_data_scaled = test_data.copy()\n",
    "test_data_scaled[columns_to_scale] = scaler.transform(test_data[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Sample:\n",
      "   trip_miles  trip_time  base_passenger_fare  tips  request_hour  \\\n",
      "0        1.18        664                24.90   0.0             0   \n",
      "1        0.82        460                11.97   0.0             0   \n",
      "2        1.18        595                29.82   0.0             0   \n",
      "3        1.65        303                 7.91   0.0             0   \n",
      "4        1.65        461                 9.44   0.0             0   \n",
      "\n",
      "   request_day_of_week  hvfhs_license_num_encoded  \n",
      "0                    5                          0  \n",
      "1                    5                          0  \n",
      "2                    5                          0  \n",
      "3                    5                          0  \n",
      "4                    5                          0  \n"
     ]
    }
   ],
   "source": [
    "print(\"Train Data Sample:\")\n",
    "print(train_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data Sample:\n",
      "         trip_miles  trip_time  base_passenger_fare  tips  request_hour  \\\n",
      "9149683        4.46        760                17.93   0.0             0   \n",
      "9149807        2.38        611                12.08   0.0             0   \n",
      "\n",
      "         request_day_of_week  hvfhs_license_num_encoded  \n",
      "9149683                    4                          0  \n",
      "9149807                    4                          0  \n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Data Sample:\")\n",
    "print(validation_data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['trip_miles', 'trip_time', 'base_passenger_fare', 'tips']] = scaler.fit_transform(\n",
    "    df[['trip_miles', 'trip_time', 'base_passenger_fare', 'tips']]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = pandas.to_datetime(df['pickup_datetime']).dt.hour\n",
    "df['day_of_week'] = pandas.to_datetime(df['pickup_datetime']).dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'base_passenger_fare'\n",
    "\n",
    "# Extract features and targets\n",
    "X_train = train_data_scaled.drop(columns=[target_column])\n",
    "y_train = train_data_scaled[target_column]\n",
    "\n",
    "X_val = validation_data_scaled.drop(columns=[target_column])\n",
    "y_val = validation_data_scaled[target_column]\n",
    "\n",
    "X_test = test_data_scaled.drop(columns=[target_column])\n",
    "y_test = test_data_scaled[target_column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    # Explicit Input Layer\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "\n",
    "    # First Hidden Layer\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Second Hidden Layer\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Third Hidden Layer\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # Output Layer\n",
    "    Dense(1, activation='linear')  # Linear activation for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m604250/604250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1751s\u001b[0m 3ms/step - loss: 0.2444 - mae: 0.3203 - val_loss: 0.4241 - val_mae: 0.2553\n",
      "Epoch 2/20\n",
      "\u001b[1m604250/604250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1921s\u001b[0m 3ms/step - loss: 0.2266 - mae: 0.3103 - val_loss: 0.5476 - val_mae: 0.2697\n",
      "Epoch 3/20\n",
      "\u001b[1m604250/604250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2195s\u001b[0m 4ms/step - loss: 0.2258 - mae: 0.3099 - val_loss: 0.2837 - val_mae: 0.2793\n",
      "Epoch 4/20\n",
      "\u001b[1m604250/604250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2278s\u001b[0m 4ms/step - loss: 0.2243 - mae: 0.3091 - val_loss: 3.0885 - val_mae: 0.3094\n",
      "Epoch 5/20\n",
      "\u001b[1m604250/604250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2345s\u001b[0m 4ms/step - loss: 0.2242 - mae: 0.3090 - val_loss: 0.4354 - val_mae: 0.2764\n",
      "Epoch 6/20\n",
      "\u001b[1m604250/604250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2031s\u001b[0m 3ms/step - loss: 0.2240 - mae: 0.3088 - val_loss: 0.4771 - val_mae: 0.2900\n",
      "Epoch 7/20\n",
      "\u001b[1m604250/604250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1967s\u001b[0m 3ms/step - loss: 0.2240 - mae: 0.3089 - val_loss: 0.6851 - val_mae: 0.2933\n",
      "Epoch 8/20\n",
      "\u001b[1m604250/604250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2017s\u001b[0m 3ms/step - loss: 0.2240 - mae: 0.3089 - val_loss: 0.4208 - val_mae: 0.2930\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m139878/139878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 1ms/step\n",
      "RMSE: 0.6976405288220727\n",
      "MAE: 0.38325424579034323\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "rmse = numpy.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
